{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ex09_Practice#3_Human Action Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOEnNy24LD+CEpBAX1pDq0l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SungjooHwang/SungjooHwang/blob/main/Ex09_Practice_3_Human_Action_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f28tsYKYTWYx"
      },
      "source": [
        "**This code is based on: https://stackabuse.com/cross-validation-and-grid-search-for-model-selection-in-python/ **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsDddg5xXZmO"
      },
      "source": [
        "**The Dataset**\n",
        "\n",
        "For the Practice #3 in the Lecture Note #09, Use 'finaldata.csv'that include acceleration signal features and labels of actions ('1' for spreading mortar, '2' for laying block, '3' for adjusting, and '4'for removing mortar)\n",
        "You can also use your own dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJuAydsQYIe3"
      },
      "source": [
        "**Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xvt8ycgYKQV"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWQRdjWeYK7r"
      },
      "source": [
        "**Importing the Dataset**\n",
        "\n",
        "Import the dataset and load it into our pandas dataframe,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FITNbe1JYTeq"
      },
      "source": [
        "dataset = pd.read_csv(\"finaldata.csv\")"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "qq9O6zYnYWVY",
        "outputId": "663fd472-ef14-468f-eb04-fcf831cf8cf0"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MeanX</th>\n",
              "      <th>MeanY</th>\n",
              "      <th>MeanZ</th>\n",
              "      <th>SkewX</th>\n",
              "      <th>SkewY</th>\n",
              "      <th>SkewZ</th>\n",
              "      <th>MaxX</th>\n",
              "      <th>MaxY</th>\n",
              "      <th>MaxZ</th>\n",
              "      <th>MinX</th>\n",
              "      <th>MinY</th>\n",
              "      <th>MinZ</th>\n",
              "      <th>RangeX</th>\n",
              "      <th>RangeY</th>\n",
              "      <th>RangeZ</th>\n",
              "      <th>stdX</th>\n",
              "      <th>stdY</th>\n",
              "      <th>stdZ</th>\n",
              "      <th>KurtosisX</th>\n",
              "      <th>KurtosisY</th>\n",
              "      <th>KurtosisZ</th>\n",
              "      <th>CorrXY</th>\n",
              "      <th>CorrYZ</th>\n",
              "      <th>CorrZX</th>\n",
              "      <th>EnergyX</th>\n",
              "      <th>EnergyY</th>\n",
              "      <th>EnergyZ</th>\n",
              "      <th>EntropyX</th>\n",
              "      <th>EntropyY</th>\n",
              "      <th>EntropyZ</th>\n",
              "      <th>action</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-22.602273</td>\n",
              "      <td>55.329545</td>\n",
              "      <td>-5.079545</td>\n",
              "      <td>-0.430630</td>\n",
              "      <td>-0.152069</td>\n",
              "      <td>0.716635</td>\n",
              "      <td>78</td>\n",
              "      <td>127</td>\n",
              "      <td>105</td>\n",
              "      <td>-128</td>\n",
              "      <td>-58</td>\n",
              "      <td>-85</td>\n",
              "      <td>206</td>\n",
              "      <td>185</td>\n",
              "      <td>190</td>\n",
              "      <td>42.338684</td>\n",
              "      <td>43.120980</td>\n",
              "      <td>28.553729</td>\n",
              "      <td>3.736030</td>\n",
              "      <td>2.443957</td>\n",
              "      <td>5.255820</td>\n",
              "      <td>-0.006740</td>\n",
              "      <td>0.185144</td>\n",
              "      <td>0.117068</td>\n",
              "      <td>77553.723366</td>\n",
              "      <td>80642.530185</td>\n",
              "      <td>35446.530185</td>\n",
              "      <td>10.118275</td>\n",
              "      <td>3.188343</td>\n",
              "      <td>19.139626</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-18.102273</td>\n",
              "      <td>58.488636</td>\n",
              "      <td>-5.340909</td>\n",
              "      <td>-0.573902</td>\n",
              "      <td>-0.193898</td>\n",
              "      <td>1.209931</td>\n",
              "      <td>75</td>\n",
              "      <td>127</td>\n",
              "      <td>105</td>\n",
              "      <td>-128</td>\n",
              "      <td>-58</td>\n",
              "      <td>-54</td>\n",
              "      <td>203</td>\n",
              "      <td>185</td>\n",
              "      <td>159</td>\n",
              "      <td>40.263511</td>\n",
              "      <td>37.033379</td>\n",
              "      <td>27.008252</td>\n",
              "      <td>4.070303</td>\n",
              "      <td>3.187264</td>\n",
              "      <td>5.999251</td>\n",
              "      <td>-0.068927</td>\n",
              "      <td>0.267239</td>\n",
              "      <td>0.278444</td>\n",
              "      <td>70430.973366</td>\n",
              "      <td>59653.646662</td>\n",
              "      <td>31609.886364</td>\n",
              "      <td>12.220491</td>\n",
              "      <td>2.672048</td>\n",
              "      <td>18.039167</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-19.681818</td>\n",
              "      <td>58.375000</td>\n",
              "      <td>-11.954545</td>\n",
              "      <td>-0.664967</td>\n",
              "      <td>0.602729</td>\n",
              "      <td>0.859530</td>\n",
              "      <td>48</td>\n",
              "      <td>127</td>\n",
              "      <td>86</td>\n",
              "      <td>-127</td>\n",
              "      <td>-6</td>\n",
              "      <td>-83</td>\n",
              "      <td>175</td>\n",
              "      <td>133</td>\n",
              "      <td>169</td>\n",
              "      <td>31.549467</td>\n",
              "      <td>31.032172</td>\n",
              "      <td>28.925949</td>\n",
              "      <td>5.124737</td>\n",
              "      <td>2.837830</td>\n",
              "      <td>4.734259</td>\n",
              "      <td>0.066632</td>\n",
              "      <td>0.359750</td>\n",
              "      <td>0.262228</td>\n",
              "      <td>43265.482955</td>\n",
              "      <td>41845.589844</td>\n",
              "      <td>36148.846591</td>\n",
              "      <td>8.392115</td>\n",
              "      <td>2.077043</td>\n",
              "      <td>11.524579</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-15.625000</td>\n",
              "      <td>55.693182</td>\n",
              "      <td>-10.590909</td>\n",
              "      <td>-0.328796</td>\n",
              "      <td>0.430409</td>\n",
              "      <td>0.291269</td>\n",
              "      <td>68</td>\n",
              "      <td>127</td>\n",
              "      <td>83</td>\n",
              "      <td>-128</td>\n",
              "      <td>-21</td>\n",
              "      <td>-83</td>\n",
              "      <td>196</td>\n",
              "      <td>148</td>\n",
              "      <td>166</td>\n",
              "      <td>34.439456</td>\n",
              "      <td>29.261547</td>\n",
              "      <td>27.805828</td>\n",
              "      <td>4.469902</td>\n",
              "      <td>3.875835</td>\n",
              "      <td>4.190040</td>\n",
              "      <td>-0.004686</td>\n",
              "      <td>0.201368</td>\n",
              "      <td>0.271803</td>\n",
              "      <td>51586.402344</td>\n",
              "      <td>37230.854048</td>\n",
              "      <td>33629.995739</td>\n",
              "      <td>11.412033</td>\n",
              "      <td>2.188670</td>\n",
              "      <td>13.520706</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-20.125000</td>\n",
              "      <td>52.295455</td>\n",
              "      <td>-16.409091</td>\n",
              "      <td>0.238599</td>\n",
              "      <td>0.372197</td>\n",
              "      <td>-0.180156</td>\n",
              "      <td>85</td>\n",
              "      <td>127</td>\n",
              "      <td>55</td>\n",
              "      <td>-128</td>\n",
              "      <td>-21</td>\n",
              "      <td>-91</td>\n",
              "      <td>213</td>\n",
              "      <td>148</td>\n",
              "      <td>146</td>\n",
              "      <td>36.542469</td>\n",
              "      <td>27.227082</td>\n",
              "      <td>24.544417</td>\n",
              "      <td>3.668240</td>\n",
              "      <td>3.833551</td>\n",
              "      <td>3.702255</td>\n",
              "      <td>-0.045861</td>\n",
              "      <td>0.286993</td>\n",
              "      <td>0.184446</td>\n",
              "      <td>58083.558594</td>\n",
              "      <td>32247.096591</td>\n",
              "      <td>25912.370739</td>\n",
              "      <td>9.665516</td>\n",
              "      <td>2.045628</td>\n",
              "      <td>7.365125</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       MeanX      MeanY      MeanZ  ...  EntropyY   EntropyZ  action\n",
              "0 -22.602273  55.329545  -5.079545  ...  3.188343  19.139626       1\n",
              "1 -18.102273  58.488636  -5.340909  ...  2.672048  18.039167       1\n",
              "2 -19.681818  58.375000 -11.954545  ...  2.077043  11.524579       1\n",
              "3 -15.625000  55.693182 -10.590909  ...  2.188670  13.520706       1\n",
              "4 -20.125000  52.295455 -16.409091  ...  2.045628   7.365125       1\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqpo7ccoYcAQ"
      },
      "source": [
        "**Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ6XKP-dYiAX"
      },
      "source": [
        "The next step is to split our dataset into its attributes and labels. \n",
        "\n",
        "The X variable contains the first 30 columns of the dataset (i.e. signal features) while y contains the labels of actions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6QfmbgiYi0_"
      },
      "source": [
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, 30].values\n",
        "# print(y)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Lisy_fSZkpX"
      },
      "source": [
        "**Feature Scaling**\n",
        "\n",
        "Before making any actual predictions, it is always a good practice to scale the features so that all of them can be uniformly evaluated. Wikipedia explains the reasoning pretty well:\n",
        "\n",
        "*Since the range of values of raw data varies widely, in some machine learning algorithms, objective functions will not work properly without normalization. For example, the majority of classifiers calculate the distance between two points by the Euclidean distance. If one of the features has a broad range of values, the distance will be governed by this particular feature. Therefore, the range of all features should be normalized so that each feature contributes approximately proportionately to the final distance.*\n",
        "\n",
        "The gradient descent algorithm (which is used in neural network training and other machine learning algorithms) also converges faster with normalized features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQbpKT6wZ0RL"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "\n",
        "X = scaler.transform(X)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCAX9rLqaDvS"
      },
      "source": [
        "**Training and Cross Validation**\n",
        "\n",
        "The first step in the training and cross validation phase is simple. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpiGeFuCaKHj"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators=300, random_state=0)\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXZ1rV-vaQB2"
      },
      "source": [
        "Next, to implement cross validation, the *cross_val_score* method of the *sklearn.model_selection* library can be used. The *cross_val_score* returns the accuracy for all the folds. The first parameter is estimator which basically specifies the algorithm that you want to use for cross validation. The second and third parameters, X and y, i.e. features and labels. Finally the number of folds is passed to the cv parameter as shown in the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MRZefNkaTbE"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "all_accuracies = cross_val_score(estimator=classifier, X=X, y=y, cv=5)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfovA0G4PfDF",
        "outputId": "a7078ef3-4801-46ec-8be0-dab8f6166047"
      },
      "source": [
        "print(all_accuracies)\n",
        "print(all_accuracies.mean())\n",
        "print(all_accuracies.std())"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.91935484 1.         0.9516129  0.8852459  0.8852459 ]\n",
            "0.9282919090428345\n",
            "0.04352403430590002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lOtpvFwapFb"
      },
      "source": [
        "**(Optional) Grid Search for Parameter Selection**\n",
        "\n",
        "A machine learning model has two types of parameters. The first type of parameters are the parameters that are learned through a machine learning model while the second type of parameters are the hyper parameter that we pass to the machine learning model.\n",
        "\n",
        "In the last section, we used the Random Forest algorithm. The number of estimators we used for the algorithm was 300. Similarly in KNN algorithm we have to specify the value of K and for SVM algorithm we have to specify the type of Kernel. These estimators - the K value and Kernel - are all types of hyper parameters.\n",
        "\n",
        "Normally we randomly set the value for these hyper parameters and see what parameters result in best performance. However randomly selecting the parameters for the algorithm can be exhaustive.\n",
        "\n",
        "Also, it is not easy to compare performance of different algorithms by randomly setting the hyper parameters because one algorithm may perform better than the other with different set of parameters. And if the parameters are changed, the algorithm may perform worse than the other algorithms.\n",
        "\n",
        "Therefore, instead of randomly selecting the values of the parameters, a better approach would be to develop an algorithm which automatically finds the best parameters for a particular model. Grid Search is one such algorithm.\n",
        "\n",
        "To implement the Grid Search algorithm we need to import GridSearchCV class from the sklearn.model_selection library.\n",
        "The first step you need to perform is to create a dictionary of all the parameters and their corresponding set of values that you want to test for best performance. The name of the dictionary items corresponds to the parameter name and the value corresponds to the list of values for the parameter.\n",
        "Let's create a dictionary of parameters and their corresponding values for our Random Forest algorithm. Details of all the parameters for the random forest algorithm are available in the Scikit-Learn docs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeoRjxYAavik"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "grid_param = {\n",
        "    'n_estimators': [100, 300, 500, 800, 1000],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'bootstrap': [True, False]\n",
        "}"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2Ncl8iBa2TW"
      },
      "source": [
        "Take a careful look at the above code. Here we create grid_param dictionary with three parameters n_estimators, criterion, and bootstrap. The parameter values that we want to try out are passed in the list. For instance, in the above script we want to find which value (out of 100, 300, 500, 800, and 1000) provides the highest accuracy.\n",
        "\n",
        "Similarly, we want to find which value results in the highest performance for the criterion parameter: \"gini\" or \"entropy\"? The Grid Search algorithm basically tries all possible combinations of parameter values and returns the combination with the highest accuracy. For instance, in the above case the algorithm will check 20 combinations (5 x 2 x 2 = 20).\n",
        "\n",
        "The Grid Search algorithm can be very slow, owing to the potentially huge number of combinations to test. Furthermore, cross validation further increases the execution time and complexity.\n",
        "\n",
        "Once the parameter dictionary is created, the next step is to create an instance of the GridSearchCV class. You need to pass values for the estimator parameter, which basically is the algorithm that you want to execute. The param_grid parameter takes the parameter dictionary that we just created as parameter, the scoring parameter takes the performance metrics, the cv parameter corresponds to number of folds, which is 5 in our case, and finally the n_jobs parameter refers to the number of CPU's that you want to use for execution. A value of -1 for n_jobs parameter means that use all available computing power. This can be handy if you have large number amount of data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccu1e8Zca3hz"
      },
      "source": [
        "gd_sr = GridSearchCV(estimator=classifier,\n",
        "                     param_grid=grid_param,\n",
        "                     scoring='accuracy',\n",
        "                     cv=5,\n",
        "                     n_jobs=-1)\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cyrgp6-eQ4iV"
      },
      "source": [
        "\n",
        "Once the GridSearchCV class is initialized, the last step is to call the fit method of the class and pass it the training  set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdkpBmknQ4pU",
        "outputId": "3963ac52-9cef-4c1f-b94e-604efd40853e"
      },
      "source": [
        "gd_sr.fit(X, y)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=300, n_jobs=None,\n",
              "                                              oob_score=False, random_state=0,\n",
              "                                              verbose=0, warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'bootstrap': [True, False],\n",
              "                         'criterion': ['gini', 'entropy'],\n",
              "                         'n_estimators': [100, 300, 500, 800, 1000]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB73etFQRIPC"
      },
      "source": [
        "Once the method completes execution, the next step is to check the parameters that return the highest accuracy. To do so, print the sr.best_params_ attribute of the GridSearchCV object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-hT5wEzRIXJ",
        "outputId": "ad5aeb5d-fbf0-44d2-f67a-1eaeb314ef80"
      },
      "source": [
        "best_parameters = gd_sr.best_params_\n",
        "print(best_parameters)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bootstrap': True, 'criterion': 'entropy', 'n_estimators': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMytqwj0RMaa"
      },
      "source": [
        "The last and final step of Grid Search algorithm is to find the accuracy obtained using the best parameters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sZB8QKWRMhZ",
        "outputId": "dc7c7da7-fbd2-4593-c34f-db5eece46040"
      },
      "source": [
        "best_result = gd_sr.best_score_\n",
        "print(best_result)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9479111581173981\n"
          ]
        }
      ]
    }
  ]
}