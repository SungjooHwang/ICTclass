{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ex11_1p.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMpP1sOYnd3G2VU429p4H4K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SungjooHwang/SungjooHwang/blob/main/Ex11_1p.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-MZNc_R-Nar"
      },
      "source": [
        "**The origninal source of this example:**\n",
        "\n",
        "**https://stackabuse.com/introduction-to-neural-networks-with-scikit-learn/**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsDddg5xXZmO"
      },
      "source": [
        "**The Dataset**\n",
        "\n",
        "The dataset that we are going to use for this tutorial is the popular Iris dataset, available at https://archive.ics.uci.edu/ml/datasets/iris. The details of the dataset are available at the aforementioned link.\n",
        "\n",
        "Let's jump straight to the code. The first step is to import this dataset into our program. To do so, we will use Python's pandas library.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJuAydsQYIe3"
      },
      "source": [
        "**Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xvt8ycgYKQV"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWQRdjWeYK7r"
      },
      "source": [
        "**Importing the Dataset**\n",
        "\n",
        "Import the dataset and load it into our pandas dataframe,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FITNbe1JYTeq"
      },
      "source": [
        "# Location of dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "\n",
        "# Assign colum names to the dataset\n",
        "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n",
        "\n",
        "# Read dataset to pandas dataframe\n",
        "irisdata = pd.read_csv(url, names=names)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "qq9O6zYnYWVY",
        "outputId": "dfcbd4a5-ea66-4931-92a5-e1240723b924"
      },
      "source": [
        "irisdata.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal-length</th>\n",
              "      <th>sepal-width</th>\n",
              "      <th>petal-length</th>\n",
              "      <th>petal-width</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal-length  sepal-width  petal-length  petal-width        Class\n",
              "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
              "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
              "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
              "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
              "4           5.0          3.6           1.4          0.2  Iris-setosa"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqpo7ccoYcAQ"
      },
      "source": [
        "**Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ6XKP-dYiAX"
      },
      "source": [
        "The task is to predict the class (which are the values in the fifth column) that the iris plant belongs to, which is based upon the sepal-length, sepal-width, petal-length and petal-width (the first four columns). The next step is to split our dataset into attributes and labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6QfmbgiYi0_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "22cfcf9e-fa96-4098-b832-cac7c2843693"
      },
      "source": [
        "# Assign data from first four columns to X variable\n",
        "X = irisdata.iloc[:, 0:4]\n",
        "\n",
        "# Assign data from first fifth columns to y variable\n",
        "y = irisdata.select_dtypes(include=[object])\n",
        "\n",
        "y.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Class\n",
              "0  Iris-setosa\n",
              "1  Iris-setosa\n",
              "2  Iris-setosa\n",
              "3  Iris-setosa\n",
              "4  Iris-setosa"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_Un9lSia5hI"
      },
      "source": [
        "You can see that the values in the y series are categorical. However, neural networks work better with numerical data. Our next task is to convert these categorical values to numerical values. But first let's see how many unique values we have in our y series."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bM1VXHkca8aw",
        "outputId": "34ab9db6-8cd0-4568-eaa6-9cc404aa25f0"
      },
      "source": [
        "y.Class.unique()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foQeUJ-wbDWT"
      },
      "source": [
        "We have three unique classes 'Iris-setosa', 'Iris-versicolor' and 'Iris-virginica'. Let's convert these categorical values to numerical values. To do so we will use Scikit-Learn's LabelEncoder class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9RUONc4bFN1"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "y = y.apply(le.fit_transform)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhy4GkynbKMv",
        "outputId": "360d4c79-4fe6-4ce0-9976-ede4113fd1e4"
      },
      "source": [
        "y.Class.unique()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jNom6vGbNN6"
      },
      "source": [
        "You can see that the categorical values have been encoded to numerical values i.e. 0, 1, and 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJHBPrcIZTFz"
      },
      "source": [
        "**Train Test Split**\n",
        "\n",
        "To avoid over-fitting, we will divide our dataset into training and test splits. The training data will be used to train the neural network and the test data will be used to evaluate the performance of the neural network. This helps with the problem of over-fitting because we're evaluating our neural network on data that it has not seen (i.e. been trained on) before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2k-hEaLZYrO"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Lisy_fSZkpX"
      },
      "source": [
        "**Feature Scaling**\n",
        "\n",
        "Before making actual predictions, it is always a good practice to scale the features so that all of them can be uniformly evaluated. Feature scaling is performed only on the training data and not on test data. This is because in real world, data is not scaled and the ultimate purpose of the neural network is to make predictions on real world data. Therefore, we try to keep our test data as real as possible.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQbpKT6wZ0RL"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCAX9rLqaDvS"
      },
      "source": [
        "**Training and Predictions**\n",
        "\n",
        "And now it's finally time to do what you have been waiting for, train a neural network that can actually make predictions.\n",
        "\n",
        "With Scikit-Learn, you can create neural network with these three lines of code, which all handles much of the leg work for you. Let's see what is happening in the above script. The first step is to import the MLPClassifier class from the sklearn.neural_network library. In the second line, this class is initialized with two parameters.\n",
        "\n",
        "The first parameter, hidden_layer_sizes, is used to set the size of the hidden layers. In our script we will create three layers of 10 nodes each. There is no standard formula for choosing the number of layers and nodes for a neural network and it varies quite a bit depending on the problem at hand. The best way is to try different combinations and see what works best.\n",
        "\n",
        "The second parameter to MLPClassifier specifies the number of iterations, or the epochs, that you want your neural network to execute. Remember, one epoch is a combination of one cycle of feed-forward and back propagation phase.\n",
        "\n",
        "By default the 'relu' activation function is used with 'adam' cost optimizer. However, you can change these functions using the activation and solver parameters, respectively.\n",
        "\n",
        "In the third line the fit function is used to train the algorithm on our training data i.e. X_train and y_train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpiGeFuCaKHj",
        "outputId": "c76abb83-f08c-4c14-e9ce-7c6b17b688bf"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)\n",
        "mlp.fit(X_train, y_train.values.ravel())\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXZ1rV-vaQB2"
      },
      "source": [
        "We created our algorithm and we made some predictions on the test dataset. Now is the time to evaluate how well our algorithm performs. To evaluate an algorithm, the most commonly used metrics are a confusion matrix, precision, recall, and f1 score. The confusion_matrix and classification_report methods of the sklearn.metrics library can help us find these scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MRZefNkaTbE"
      },
      "source": [
        "predictions = mlp.predict(X_test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErXpX5j2aVAQ"
      },
      "source": [
        "**Evaluating the Algorithm**\n",
        "\n",
        "\n",
        "We created our algorithm and we made some predictions on the test dataset. Now is the time to evaluate how well our algorithm performs. To evaluate an algorithm, the most commonly used metrics are a confusion matrix, precision, recall, and f1 score. The confusion_matrix and classification_report methods of the sklearn.metrics library can help us find these scores.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP04LeZ4akWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76cf185a-acd9-4626-cf5d-69272e44ace1"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test,predictions))\n",
        "print(classification_report(y_test,predictions))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8  1  0]\n",
            " [ 0 11  1]\n",
            " [ 0  0  9]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94         9\n",
            "           1       0.92      0.92      0.92        12\n",
            "           2       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.93        30\n",
            "   macro avg       0.94      0.94      0.94        30\n",
            "weighted avg       0.94      0.93      0.93        30\n",
            "\n"
          ]
        }
      ]
    }
  ]
}